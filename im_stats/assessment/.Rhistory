fit(data = train_data)
# === Step 10: Predict on Test Data ===
predictions <- predict(final_tree_fit, new_data = test_data) %>%
bind_cols(test_data)
# === Step 11: Evaluate Model Performance ===
rmse_result <- rmse(predictions, truth = Q87C, estimate = .pred)
print(paste("Test RMSE:", round(rmse_result$.estimate, 3)))
# === Step 12: Prune the Tree Using Optimal CP ===
# Extract the fitted tree model
final_tree_model <- extract_fit_engine(final_tree_fit)
# Select the best CP for pruning
optimal_cp <- final_tree_model$cptable[which.min(final_tree_model$cptable[, "xerror"]), "CP"]
# Prune the tree
pruned_tree <- prune(final_tree_model, cp = optimal_cp)
# === Step 13: Plot the Pruned Tree ===
# rpart.plot(pruned_tree, roundint = FALSE) <- Choosing not to print due to many levels.
# === Step 14: Plot Variable Importance ===
vip::vip(pruned_tree, num_features = 10) +
labs(
y = "Coefficient Magnitude",
x = "Predictor Variables",
caption = "Note: Generated using the regression tree model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif") +
theme(
axis.title.x = element_text(size = 10, margin = margin(t = 10))
)
# === Random Forest Model ===
# === Step 1: Fit the Random Forest Model ===
# Using the training data, fit the random forest model
rf_model <- randomForest(
Q87C ~ .,             # Model formula (predict Q87C)
data = train_data,    # Training data
ntree = 1000,         # Number of trees
mtry = 4              # Number of variables randomly sampled at each split
)
# Load the necessary packages.
# Install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# Load and install required packages using pacman for efficient package management
pacman::p_load(
# Data manipulation and wrangling
dplyr,        # Data manipulation (filter, select, mutate, etc.)
tidyr,        # Data tidying (pivoting, reshaping data)
tidyverse,    # Collection of R packages for data science (includes dplyr, ggplot2, tidyr, readr, etc.)
janitor,      # Cleaning data (e.g., cleaning column names, tabulations)
# Data import/export
readr,        # Reading and writing CSV and other text data
haven,        # Importing and exporting SPSS, Stata, and SAS files
# Data visualisation
ggplot2,      # Data visualisation (base for plots)
ggthemes,     # Additional themes for ggplot2 visualisation
ggeffects,    # Predicted marginal effects plots for regression models
dotwhisker,   # Visualisation of regression model output (dot-and-whisker plots)
scales,       # Scaling and formatting of axes and legends in plots
tikzDevice,   # Exporting high-quality LaTeX-compatible graphics
vip,          # Variable importance plots for machine learning models
# Regression analysis and statistical modelling
MASS,         # Statistical functions and distributions (e.g., Negative Binomial regression)
pscl,         # Political science models (e.g., zero-inflated and hurdle models)
brant,        # Brant test for proportional odds assumption in ordinal regression
broom,        # Tidying model outputs for analysis and visualisation
glmnet,       # Regularised regression models (LASSO, Ridge, Elastic Net)
rpart,        # Recursive partitioning for classification and regression trees
rpart.plot,   # Visualising rpart models (decision trees)
randomForest, # Random forests for classification and regression
# Machine learning and model evaluation
tidymodels,   # Framework for machine learning workflows
caret,        # Machine learning model training and cross-validation
yardstick,    # Model evaluation metrics (accuracy, precision, recall, etc.)
# Model reporting and presentation
modelsummary, # Automated model summary tables
knitr,        # Dynamic report generation (integrates with RMarkdown)
kableExtra    # Enhanced table formatting for knitr/kable outputs
)
# === Random Forest Model ===
# === Step 1: Fit the Random Forest Model ===
# Using the training data, fit the random forest model
rf_model <- randomForest(
Q87C ~ .,             # Model formula (predict Q87C)
data = train_data,    # Training data
ntree = 1000,         # Number of trees
mtry = 4              # Number of variables randomly sampled at each split
)
# === Step 3: View Variable Importance ===
importance(rf_model)    # View variable importance numerically
# Plot variable importance
vip::vip(rf_model, num_features = 10) +
labs(
title = "Top 10 Important Predictors for Attitudes Towards LGBTI Neighbours",
x = "Predictor Variables",
y = "Importance"
) +
theme_classic(base_family = "serif")
class(final_tree_model)
update.packages(ask = FALSE, checkBuilt = TRUE)
# === Step 4: Predict on Test Data ===
# Assuming 'test_data' is the testing dataset
pred_rf <- predict(rf_model, newdata = test_data)
# === Step 5: Calculate Mean Squared Error (MSE) ===
rf_mse <- mean((test_data$Q87C - pred_rf)^2)
print(paste("Random Forest MSE:", round(rf_mse, 3)))
# MSE for LASSO
mse_lasso <- mean((test_data$Q87C - pred_lasso)^2)
pred_rf <- predict(rf_model, newdata = test_data)
vip::vip(rf_model, num_features = 10) +
labs(
title = "Top 10 Important Predictors for Attitudes Towards LGBTI Neighbours",
x = "Predictor Variables",
y = "Importance"
) +
theme_classic(base_family = "serif")
vip::vip(rf_model, num_features = 10) +
labs(
x = "Predictor Variables",
y = "Importance"
Note: "Note: Generated using the Random Forest model. Variables with higher importance contribute more to the prediction."
vip::vip(rf_model, num_features = 10) +
labs(
x = "Predictor Variables",
y = "Importance",
Note: "Note: Generated using the Random Forest model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif")
vip::vip(rf_model, num_features = 10) +
labs(
x = "Predictor Variables",
y = "Importance",
caption: "Note: Generated using the Random Forest model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif")
vip::vip(pruned_tree, num_features = 10) +
labs(
y = "Coefficient Magnitude",
x = "Predictor Variables",
caption = "Note: Generated using the regression tree model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif") +
theme(
axis.title.x = element_text(size = 10, margin = margin(t = 10))
vip::vip(pruned_tree, num_features = 10) +
# Load the necessary packages.
# Install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# Load and install required packages using pacman for efficient package management
pacman::p_load(
# Data manipulation and wrangling
dplyr,        # Data manipulation (filter, select, mutate, etc.)
tidyr,        # Data tidying (pivoting, reshaping data)
tidyverse,    # Collection of R packages for data science (includes dplyr, ggplot2, tidyr, readr, etc.)
janitor,      # Cleaning data (e.g., cleaning column names, tabulations)
# Data import/export
readr,        # Reading and writing CSV and other text data
haven,        # Importing and exporting SPSS, Stata, and SAS files
# Data visualisation
ggplot2,      # Data visualisation (base for plots)
ggthemes,     # Additional themes for ggplot2 visualisation
ggeffects,    # Predicted marginal effects plots for regression models
dotwhisker,   # Visualisation of regression model output (dot-and-whisker plots)
scales,       # Scaling and formatting of axes and legends in plots
tikzDevice,   # Exporting high-quality LaTeX-compatible graphics
vip,          # Variable importance plots for machine learning models
# Regression analysis and statistical modelling
MASS,         # Statistical functions and distributions (e.g., Negative Binomial regression)
pscl,         # Political science models (e.g., zero-inflated and hurdle models)
brant,        # Brant test for proportional odds assumption in ordinal regression
broom,        # Tidying model outputs for analysis and visualisation
glmnet,       # Regularised regression models (LASSO, Ridge, Elastic Net)
rpart,        # Recursive partitioning for classification and regression trees
rpart.plot,   # Visualising rpart models (decision trees)
randomForest, # Random forests for classification and regression
# Machine learning and model evaluation
tidymodels,   # Framework for machine learning workflows
caret,        # Machine learning model training and cross-validation
yardstick,    # Model evaluation metrics (accuracy, precision, recall, etc.)
# Model reporting and presentation
modelsummary, # Automated model summary tables
knitr,        # Dynamic report generation (integrates with RMarkdown)
kableExtra    # Enhanced table formatting for knitr/kable outputs
)
vip::vip(pruned_tree, num_features = 10) +
labs(
y = "Coefficient Magnitude",
x = "Predictor Variables",
caption = "Note: Generated using the regression tree model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif") +
theme(
axis.title.x = element_text(size = 10, margin = margin(t = 10))
)
vip::vip(rf_model, num_features = 10) +
labs(
x = "Predictor Variables",
y = "Importance",
caption: "Note: Generated using the Random Forest model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif")
?vip
?labs
# Plot variable importance
vip::vip(rf_model, num_features = 10) +
labs(
x = "Predictor Variables",
y = "Importance",
caption = "Note: Generated using the Random Forest model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif")
# Select the best CP for pruning
optimal_cp <- final_tree_model$cptable[which.min(final_tree_model$cptable[, "xerror"]), "CP"]
# Prune the tree
pruned_tree <- rpart::prune(final_tree_model, cp = optimal_cp)
# === Step 13: Plot the Pruned Tree ===
part.plot(pruned_tree, roundint = FALSE)
vip::vip(pruned_tree, num_features = 10) +
labs(
y = "Coefficient Magnitude",
x = "Predictor Variables",
caption = "Note: Generated using the regression tree model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif") +
theme(
plot.margin = ggplot2::margin(t = 10, r = 10, b = 10, l = 10)
)
# Summary statistics for gun ownership by political affiliation.
# Calculate the percentage of gun ownership within each political group
data_percent <- gun_data %>%
filter(!is.na(gun), !is.na(pid)) %>%  # Exclude missing values
group_by(pid, gun) %>%
summarise(count = n(), .groups = "drop") %>%  # Count the number in each group
group_by(pid) %>%
mutate(percentage = (count / sum(count)) * 100)  # Calculate percentage
# === Model Comparison ===
# Predicting for random forest
pred_rf <- predict(rf_model, newdata = test_data)
# Calculate RMSE for Random Forest
rf_rmse <- sqrt(mean((test_data$Q87C - pred_rf)^2))
print(paste("Random Forest RMSE:", round(rf_rmse, 3)))
# Calculate RMSE for LASSO model
pred_lasso <- predict(final_lasso_model, newx = X_test, s = best_lambda)
lasso_rmse <- sqrt(mean((y_test - pred_lasso)^2))
print(paste("LASSO RMSE:", round(lasso_rmse, 3)))
# Calculate RMSE for Regression Tree model
pred_tree <- predict(final_tree_fit, new_data = test_data)$.pred
tree_rmse <- sqrt(mean((test_data$Q87C - pred_tree)^2))
print(paste("Regression Tree RMSE:", round(tree_rmse, 3)))
# Load the afrobaromater.csv file
africa_data <- read_csv("afrobarometer.csv")
# View the data
view(africa_data)
# View the first few rows of the data
head(africa_data, n = 10)
# Check the structure of the data and check variable names
unique(africa_data$REGION)
sapply(africa_data, class)
# Clean the data by removing missing values
africa_data_clean <- africa_data %>%
filter(!is.na(Q87C), !is.na(REGION))
# Convert REGION to dummy variables
africa_model_data <- model.matrix(Q87C ~ . - 1, data = africa_data_clean)
# Load the afrobaromater.csv file
africa_data <- read_csv("afrobarometer.csv")
# View the first few rows of the data
head(africa_data, n = 10)
# Check the structure of the data and check variable names
unique(africa_data$REGION)
sapply(africa_data, class)
# Clean the data by removing missing values
africa_data_clean <- africa_data %>%
filter(!is.na(Q87C), !is.na(REGION))
# Convert REGION to dummy variables
africa_model_data <- model.matrix(Q87C ~ . - 1, data = africa_data_clean)
# Load the afrobaromater.csv file
africa_data <- read_csv("afrobarometer.csv")
# Clean the data by removing missing values
africa_data_clean <- africa_data %>%
filter(!is.na(Q87C), !is.na(REGION))
# Convert REGION to dummy variables
africa_model_data <- model.matrix(Q87C ~ . - 1, data = africa_data_clean)
# Load the afrobaromater.csv file
africa_data <- read_csv("afrobarometer.csv")
# Load the afrobaromater.csv file
africa_data <- read_csv("afrobarometer.csv")
# Load the afrobaromater.csv file
africa_data <- read_csv("afrobarometer.csv", show_col_types = FALSE)
# Clean the data by removing missing values
africa_data_clean <- africa_data %>%
filter(!is.na(Q87C), !is.na(REGION))
# Convert REGION to dummy variables
africa_model_data <- model.matrix(Q87C ~ . - 1, data = africa_data_clean)
# Load the afrobaromater.csv file
africa_data <- read_csv("afrobarometer.csv", show_col_types = FALSE)
# Clean the data by removing missing values
africa_data_clean <- africa_data %>%
filter(!is.na(Q87C), !is.na(REGION))
# Convert REGION to dummy variables
africa_model_data <- model.matrix(Q87C ~ . - 1, data = africa_data_clean)
importance(rf_model)    # View variable importance numerically
invisible(importance(rf_model))    # View variable importance numerically
# === Model Comparison ===
# Predicting for random forest
pred_rf <- predict(rf_model, newdata = test_data)
# Calculate RMSE for Random Forest
rf_rmse <- sqrt(mean((test_data$Q87C - pred_rf)^2))
invisible(print(paste("Random Forest RMSE:", round(rf_rmse, 3))))
# Calculate RMSE for LASSO model
pred_lasso <- predict(final_lasso_model, newx = X_test, s = best_lambda)
lasso_rmse <- sqrt(mean((y_test - pred_lasso)^2))
invisible(print(paste("LASSO RMSE:", round(lasso_rmse, 3))))
# Calculate RMSE for Regression Tree model
pred_tree <- predict(final_tree_fit, new_data = test_data)$.pred
tree_rmse <- sqrt(mean((test_data$Q87C - pred_tree)^2))
invisible(print(paste("Regression Tree RMSE:", round(tree_rmse, 3))))
# === Model Comparison ===
# Predicting for random forest
pred_rf <- predict(rf_model, newdata = test_data)
# Calculate RMSE for Random Forest
rf_rmse <- sqrt(mean((test_data$Q87C - pred_rf)^2))
invisible(print(paste("Random Forest RMSE:", round(rf_rmse, 3))))
# Calculate RMSE for LASSO model
pred_lasso <- predict(final_lasso_model, newx = X_test, s = best_lambda)
lasso_rmse <- sqrt(mean((y_test - pred_lasso)^2))
invisible(print(paste("LASSO RMSE:", round(lasso_rmse, 3))))
# Calculate RMSE for Regression Tree model
pred_tree <- predict(final_tree_fit, new_data = test_data)$.pred
tree_rmse <- sqrt(mean((test_data$Q87C - pred_tree)^2))
invisible(print(paste("Regression Tree RMSE:", round(tree_rmse, 3))))
# === Model Comparison ===
# Predicting for random forest
pred_rf <- predict(rf_model, newdata = test_data)
# Calculate RMSE for Random Forest
rf_rmse <- sqrt(mean((test_data$Q87C - pred_rf)^2))
# Calculate RMSE for LASSO model
pred_lasso <- predict(final_lasso_model, newx = X_test, s = best_lambda)
lasso_rmse <- sqrt(mean((y_test - pred_lasso)^2))
# Calculate RMSE for Regression Tree model
pred_tree <- predict(final_tree_fit, new_data = test_data)$.pred
tree_rmse <- sqrt(mean((test_data$Q87C - pred_tree)^2))
# === Step 14: Plot Variable Importance ===
vip::vip(pruned_tree, num_features = 10) +
labs(
y = "Coefficient Magnitude",
x = "Predictor Variables",
caption = "Note: Generated using the regression tree model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif") +
theme(
axis.title.x = element_text(size = 10, margin = ggplot2::margin(t = 10)),
axis.title.y = element_text(size = 10),
plot.margin = ggplot2::margin(t = 10, r = 10, b = 10, l = 10)
)
# === LASSO Regression Model ===
set.seed(9999)  # Set seed for reproducibility
# === Step 1: Split the data  ===
# Define response and predictors
y <- africa_data_clean$q87c
X <- africa_model_data
# Split the data into training and testing -> 80% training, 20% testing. We do this to see if the model can make accurate predictions on new data.
data_split <- initial_split(africa_data_clean, prop = 0.8)
train_data <- training(data_split)
test_data  <- testing(data_split)
# Extract response and predictors for training and testing
X_train <- model.matrix(Q87C ~ . - 1, data = train_data)
X_test  <- model.matrix(Q87C ~ . - 1, data = test_data)
y_train <- train_data$Q87C
y_test  <- test_data$Q87C
# === Step 2: Fit the LASSO model  ===
# Set up 5-fold cross-validation. Here the data is split into 5 parts (folds) and the model is trained on 4 parts and tested on the 5th part. With the average performance being used to improve accuracy.
cv_folds <- vfold_cv(train_data, v = 5)
# Train the LASSO model with cross-validation
lasso_model <- train(
x = X_train,
y = y_train,
method = "glmnet",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = expand.grid(
alpha = 1,  # LASSO penalty, this tells the model to shrink less important predictors to zero (removing them)
lambda = seq(0.001, 1, by = 0.01)  # Regularisation parameter, this tells the model how much to penalise the coefficients
)
)
# === Step 3: Model Evaluation  ===
# Extract the best lambda value from cross-validation
best_lambda <- lasso_model$bestTune$lambda
# Fit the final LASSO model using the best lambda
final_lasso_model <- glmnet(
x = X_train,
y = y_train,
alpha = 1,         # LASSO regression
lambda = best_lambda
)
# === Step 4: Fit the LASSO model with the best lambda  ===
# Extract the coefficients from the LASSO model and plot using vip (Variable Importance in Projection)
# Unfortunately I could not find a way to easily rename the lavels of the variables without getting multiple console warnings.
vip::vip(final_lasso_model, num_features = 10, lambda = best_lambda) +
labs(
x = "Predictor Variables",
y = "Coefficient Magnitude",
caption = "Note: Generated using the LASSO regression model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif") +
theme(
aaxis.title.x = element_text(size = 10, margin = ggplot2::margin(t = 10)),
axis.title.y = element_text(size = 10),
plot.margin = ggplot2::margin(t = 10, r = 20, b = 20, l = 20)
)
# === LASSO Regression Model ===
set.seed(9999)  # Set seed for reproducibility
# === Step 1: Split the data  ===
# Define response and predictors
y <- africa_data_clean$q87c
X <- africa_model_data
# Split the data into training and testing -> 80% training, 20% testing. We do this to see if the model can make accurate predictions on new data.
data_split <- initial_split(africa_data_clean, prop = 0.8)
train_data <- training(data_split)
test_data  <- testing(data_split)
# Extract response and predictors for training and testing
X_train <- model.matrix(Q87C ~ . - 1, data = train_data)
X_test  <- model.matrix(Q87C ~ . - 1, data = test_data)
y_train <- train_data$Q87C
y_test  <- test_data$Q87C
# === Step 2: Fit the LASSO model  ===
# Set up 5-fold cross-validation. Here the data is split into 5 parts (folds) and the model is trained on 4 parts and tested on the 5th part. With the average performance being used to improve accuracy.
cv_folds <- vfold_cv(train_data, v = 5)
# Train the LASSO model with cross-validation
lasso_model <- train(
x = X_train,
y = y_train,
method = "glmnet",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = expand.grid(
alpha = 1,  # LASSO penalty, this tells the model to shrink less important predictors to zero (removing them)
lambda = seq(0.001, 1, by = 0.01)  # Regularisation parameter, this tells the model how much to penalise the coefficients
)
)
# === Step 3: Model Evaluation  ===
# Extract the best lambda value from cross-validation
best_lambda <- lasso_model$bestTune$lambda
# Fit the final LASSO model using the best lambda
final_lasso_model <- glmnet(
x = X_train,
y = y_train,
alpha = 1,         # LASSO regression
lambda = best_lambda
)
# === Step 4: Fit the LASSO model with the best lambda  ===
# Extract the coefficients from the LASSO model and plot using vip (Variable Importance in Projection)
# Unfortunately I could not find a way to easily rename the lavels of the variables without getting multiple console warnings.
vip::vip(final_lasso_model, num_features = 10, lambda = best_lambda) +
labs(
x = "Coefficient Magnitude",
y = "Predictor Variables",
caption = "Note: Generated using the LASSO regression model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif") +
theme(
aaxis.title.x = element_text(size = 10, margin = ggplot2::margin(t = 10)),
axis.title.y = element_text(size = 10),
plot.margin = ggplot2::margin(t = 10, r = 20, b = 20, l = 20)
)
# === LASSO Regression Model ===
set.seed(9999)  # Set seed for reproducibility
# === Step 1: Split the data  ===
# Define response and predictors
y <- africa_data_clean$q87c
X <- africa_model_data
# Split the data into training and testing -> 80% training, 20% testing. We do this to see if the model can make accurate predictions on new data.
data_split <- initial_split(africa_data_clean, prop = 0.8)
train_data <- training(data_split)
test_data  <- testing(data_split)
# Extract response and predictors for training and testing
X_train <- model.matrix(Q87C ~ . - 1, data = train_data)
X_test  <- model.matrix(Q87C ~ . - 1, data = test_data)
y_train <- train_data$Q87C
y_test  <- test_data$Q87C
# === Step 2: Fit the LASSO model  ===
# Set up 5-fold cross-validation. Here the data is split into 5 parts (folds) and the model is trained on 4 parts and tested on the 5th part. With the average performance being used to improve accuracy.
cv_folds <- vfold_cv(train_data, v = 5)
# Train the LASSO model with cross-validation
lasso_model <- train(
x = X_train,
y = y_train,
method = "glmnet",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = expand.grid(
alpha = 1,  # LASSO penalty, this tells the model to shrink less important predictors to zero (removing them)
lambda = seq(0.001, 1, by = 0.01)  # Regularisation parameter, this tells the model how much to penalise the coefficients
)
)
# === Step 3: Model Evaluation  ===
# Extract the best lambda value from cross-validation
best_lambda <- lasso_model$bestTune$lambda
# Fit the final LASSO model using the best lambda
final_lasso_model <- glmnet(
x = X_train,
y = y_train,
alpha = 1,         # LASSO regression
lambda = best_lambda
)
# === Step 4: Fit the LASSO model with the best lambda  ===
# Extract the coefficients from the LASSO model and plot using vip (Variable Importance in Projection)
# Unfortunately I could not find a way to easily rename the lavels of the variables without getting multiple console warnings.
vip::vip(final_lasso_model, num_features = 10, lambda = best_lambda) +
labs(
y = "Coefficient Magnitude",
x = "Predictor Variables",
caption = "Generated using the LASSO regression model. Variables with higher importance contribute more to the prediction."
) +
theme_classic(base_family = "serif") +
theme(
aaxis.title.x = element_text(size = 10, margin = ggplot2::margin(t = 10)),
axis.title.y = element_text(size = 10),
plot.margin = ggplot2::margin(t = 10, r = 20, b = 20, l = 20)
)
