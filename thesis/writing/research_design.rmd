---
title: "MPhil Politics, Comparative Government"
author: "Edward Anders"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
    bookdown::pdf_document2:
        fig_width: 6
        fig_height: 4
        fig_caption: true
        toc: false
        toc_depth: 2
        number_sections: true
        includes:
            keep_tex: false
            in_header:
                header.tex
documentclass: article
zotero: true
link-citations: true
csl: /Users/edwardanders/Documents/GitHub/oxford/metadata/harvard-cite-them-right.csl
bibliography: /Users/edwardanders/Documents/GitHub/oxford/metadata/zotero_library.bib
header-includes:
  - \usepackage{setspace}
  - \setstretch{1.5}
  - \usepackage[para]{threeparttable}
  - \usepackage[margin=1in]{geometry}
  - \setlength{\footnotesep}{1em}
  - \setlength{\skip\footins}{2em}
urlcolor: blue
linkcolor: blue
---

```{r setup, include=FALSE}
source("../analysis/packages.R")
source("../analysis/data.R")
source("../analysis/data_cleaning.R")
```

\newpage
\pagenumbering{roman}
\setcounter{page}{1}

# Abstract {-}

\newpage
\tableofcontents

\newpage
# List of Tables {-}
\listoftables

\newpage
# List of Figures {-}
\listoffigures

\newpage
\mainmatter
\pagenumbering{arabic}
\setcounter{page}{1}

# Introduction {#sec-intro}

# Literature Review {#sec-lit-review}

# Theoretical Framework {#sec-theory}

## Theory and Argumentation

- Develop the initial arguments and theoretical framework of your project.
- Discuss how your project relates to existing theoretical approaches in the literature and how these are further developed and/or applied in your research.
- This theoretical framework will most likely only be at the preliminary stage, but it is important to outline the relationships between the key actors or variables in your project.
- This ‘model’ does not have to be formal and explicit, but you may find it helpful to specify causal relationships in terms of dependent variable(s) (the outcome) and independent variables (the explanatory factors).
- Formulate some preliminary testable hypotheses derived from this ‘model’.
- Outline the key assumptions of your argument, as well as the limits to your topic (temporally and spatially).

## Hypotheses

- The hypotheses provided should state the relationship(s) expected to be observed between variables being used
- The formulation of a hypothesis should make clear whether it involves one- or two-tailed tests (i.e. predict an increase, decrease, or change in the outcome variable)
- There are two types of hypotheses to consider:
    - **Confirmatory Hypotheses**
        - The main focus of the study → what the study is designed to test
        - There should be well-powered analyses of this hypothesis
        - Should be backed up by strong theory leading to hypotheses *a priori*
    - **Exploratory Hypotheses**
        - Hypotheses wish to test but are not the main focus of the study
        - Often seen as secondary hypotheses looking at mechanisms, subgroups, heterogeneous effects, or downstream outcomes
- Should include as many hypotheses as relate to your theory or intervention
- With more than one hypothesis you will need to specify a procedure for handling multiple hypotheses in the inference criteria section of your PAP

Use the paper Affect, Not Ideology: A Social Identity Perspective on Polarization to look at theory.
As is The Origins and Consequences of Affective Polarization in the United States.
    This has a lot of criqtues of the measures of polarization too.


# Case Selection and Data Gathering {#sec-case-selection}

## Outcome Measures {#sec-outcome-measures}

The measures required to understand AI's affect on affective polarisation are multi-faceted. Different measures can be used to understand the primary outcome of affective polarisation; however, the implication of each measure differs. @druckman2019 clearly outline the best practices for these affective polarisation measures, and how the measures interact. Therefore, this research chooses to follow these measurement recommendations for use in survey self-reporting [@iyengar2019].

The most common measure of someone's identifiction with a political party is through a feeling thermometer score. This aims to understand how warmly or coldly someone feels towards the political parties they most and leat prefer. The thermometer scores are measured on a scale of `0` to `100`, where `0` is the coldest and `100` is the warmest.[^thermo-scale] This survey experiment firstly asks respondents to identify their most and least preferred party (`mostlikely` and `leastlikely`), allowing for in- and out-party identities to be exposed. We then ask respondents to firstly rate how warmly they feel towards each of these party's leaders, `MLthermo_XY` and `LLthermo_XY`, where `XY` is replaced by each party leader's initials. The use of party-leader thermometers is a common measure, leaning on valence theory's emphasis on the importance of party leaders in shaping party identification and voting behaviour [@garzia2023].[^green-leaders] Moreover, Druckman and Levendusky's (2019: 119) findings show that respondents are more  negative towards party elites rather than party voters; thus, the focus on party leaders here helps elicit the more visceral feelings. Alongside these in- and out-group measures, a net-difference score (`thermo_gap`) is also calculated as the difference between the thermometer scores (`MLthermoMean - LLthermoMean`) [@iyengar2012].

The next indicator of affective polarisation is a trait-based rating. This measure identifies the traits that respondents associate with opposing parties [@garrett2014]. The limited scope of the survey experiment meant we focussed on the trait of positive trait of *respect*, and whether respondents associated this trait with oppossing parties. Respondents were asked: "To what extent do you agree or disagree with the following statement: `[leastlikely]` party voters respect my political beliefs and opinions." This question — coded as `agreedisagree` — was asked in a Likert scale format of levels of agreement.[^codebook]

Additionally, a similar trait-based measure focussed on *trust* was used [@levendusky2013]. Here, we ask "And how much of the time do you think you can trust `[leastlikely]` party to do what is right for the country?". This question was also asked in a Likert scale format, with the options of `Almost never`, `Once in a while`, `About half of the time`, `Most of the time`, and `Always`. This measure is coded as `xtrust`. Along with the themometer score, the trait-based views of respect, and trust in opposing parties, Druckman and Levendusky (2019: 119) argue that these measures are good, general measures of prejudices held towards opposing parties.

On the other hand, affective polarisation should also be interested in actual tangible discriminatory behaviour. Therefore an emotional, social-distance-based question is included to understand how comfortable respondents are with having opposing partisans in their lives. For example, @iyengar2012 popularised the use of the @almond1963 five-nation survey question "Suppose you had a child who was getting married. How would you feel if they married a `[leastlikely]` party voter?". Coded as `child`, respondents were given options of `Extremely upset`, `Somewhat upset`, `Neither happy nor upset`, `Somewhat happy`, and `Extremely happy`.

[^thermo-scale]: The wording for the theremoeter score questions is as follows: "We’d like to get your feelings toward some of our political leaders and other groups who are in the news these days. On the next page, we’ll ask you to do that using a 0 to 100 scale that we call a feeling thermometer. Ratings between 50 degrees and 100 degrees mean that you feel favourable and warm toward the person. Ratings between 0 degrees and 50 degrees mean that you don't feel favourable toward the person and that you don't care too much for that person. You would rate the person at the 50-degree mark if you don't feel particularly warm or cold toward the person."
[^green-leaders]: The Green Party has two co-leaders, Carla Denyer and Adrian Ramsay. Therefore, ratings of both leaders are asked, and the thermometer scores for the Green Party are averaged to create a single score for the party. The variables `MLthermoMean` and `LLthermoMean` are used as the final thermometer measures for in- and out-group thermometer scores.

[^codebook]: A full breakdown of the survey experiment variables and values can be found in the codebook \hyperref[sec-codebook]{Section \ref*{sec-codebook}} in the appendix.

- See pre-analysis plan for details of what to include in this section
- Case selection (why focus on the UK?)
    - I am to have external validity to my research/case?
    - Can I make inferences to other cases?
- What is the case?
    - What is the unit of analysis?
    - What is the time period?
    - What is the geographical scope?
    - What are the key variables?
- What data is being collected?
- How is the data being collected?
    - What is the sampling strategy?
    - Note the UK weighting

- Plan for using agentic modelling
    - Why would I use agentic modelling?
    - What is the agentic modelling?
    - How will I use agentic modelling?

- Note the use of a between-subjects survey experiment
    - Deliberately chosen to avoid sensitivity issues noted by @levendusky2021

# Data analysis {#sec-data-analysis}

The following data analyses focus on all outcome measures of affective polarisation to give a holistic understading of both general and tangible prejudices, and discriminatory behaviours towards the opposing out-group to that of the respondent's identified in-group. The analysis is split by the treatments being tested: AI-generated content and AI-labelled content. Each treatment is analysed across the outcome measures of thermometer scores, trait-based measures, and social-distance measures.

## Regression Specification {#sec-reg-spec}

To test the causal Average Treatment Effect (ATE) of respondents being exposed to AI-generated and AI-lebelled content on the set of affective polarisation measures, a series of regression models are estimated. The model specification is given by Equation \@ref(eq:reg-spec):

\begin{equation}
Y_i = \beta_0 + \beta_1 D_i + \beta_2 \mathbf{X}_i + \beta_3 (D_i \times \mathbf{Z}_i) + \varepsilon_i (\#eq:reg-spec)
\end{equation}

*where:*

- $Y_i$ takes the outcome variables (`thermo_gap`, `MLthermoMean`, `LLthermoMean`, `agreedisagree`, `xtrust`, and `child`)
- $D_i$ is the treatment recieved (`ai_treatment` or `label_treatment`)
- $\mathbf{X}_i$ is a vector of covariates (see Balance Check in \hyperref[sec-balance]{Section \ref*{sec-balance}} for details)
- $\mathbf{Z}_i$ is a vector of possible interaction terms between the treatment and moderators
- $\varepsilon_i$ is the error term

In this full specitifcation, $\beta_1$ estimates the average treatment effect when the moderator(s) are at their reference level. Estimates are calculated with survey-weighted least squares and ordinal logistic models so results can be generalised to the UK more broadly. $\beta_2$ measures the effect of a one-unit change of a covariate on the outcome variable. $\beta_3$ captures the treatment effect heterogeneity across different sub-groups of the moderator, where statistically significant non-zero values suggest the ATE is different for different sub-group characteristics.

## AI-Generated Content Treatment {#sec-ai-treatment}

The results show no statistically significant treatment effect of AI-generated content on in- and out-party, nor net-difference thermometer scores. However, it is found that Liberal Democrat voters are significantly susceptible to being polarised from expsure to AI-generated content. Trait-based ratings of opposing parties/voters' respect and trust show...

### Thermometer Analysis {#sec-thermo-analysis}

Thermometer analysis is one of the primary affective polarisation measures. Before determining a causal link between AI content exposure and the affective polarisation measures, a descriptive summary of the `thermo_gap` measures, averaged over all in- and out-party leaders, given for both treatments is presented in \hyperref[fig:thermo-graph]{Figure \ref*{fig:thermo-graph}}. This shows how net-difference thermometer scores are similar across both control and treatment groups, suggesting causal effects are likely to be minimal.

```{r save-thermo-graph, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
source("../analysis/descriptive_analysis.R")
save_thermo_gap_plot(
    yougov_data,
    file = "../outputs/figures/thermo_gap_plot.pdf",
    width = 5,
    height = 3
)
```

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../outputs/figures/thermo_gap_plot.pdf}
    \caption{Average in- and out-party thermometer net-difference scores}
    \label{fig:thermo-graph}
\end{figure}

To test whether this descriptive expectation is causally salient, models for the outcome variables for in- and out-party, and net-difference thermometer scores are estimated. The thermometer outcome scores are continuous measures. Therefore, survey-weighted least squares regression models are estimated.

ATE models are presented in \hyperref[tab:thermo-results]{Table \ref*{tab:thermo-results}} for the outcome `thermo_gap`.[^thermo-outcomes] A first model (1) sets the benchmark without control for covariates and moderators. A full balanace check (\hyperref[sec-balance]{Section \ref*{sec-balance}}) shows that the treatment and control groups were balanced across all convariates. Despite this, model (2) still includes a full set of pre-treatment covariates as each has theoretical justification for affecting the outcome independently of the treatment, and also to ensure the ATE estimates are efficient. To avoid multicollinearity, individual moderators were sequentially tested within the models; however, few showed any moderation effects. The moderators of party affiliation/warmth (`mostlikely`) and attentivness to politics (`political_attention`) showed the greatest moderation effects, thus are included in the final model (3) as interaction terms to test these groups for heterogeneity.

[^thermo-outcomes]: The full models for the outcome variables of `MLthermoMean` and `LLthermoMean` are available in the appendix in \hyperref[tab:thermo-ml-results]{Table \ref*{tab:thermo-ml-results}} and \hyperref[tab:thermo-ll-results]{Table \ref*{tab:thermo-ll-results}}.

```{r fit-thermo-models, echo=FALSE, message=FALSE, results='hide'}
source("../analysis/thermo_models.R")
source("../analysis/survey_design.R")

# Fit all required thermometer models in a single step
thermo_models_list <- fit_thermo_models(yougov_data, yougov_design)

# Assign objects for easier referencing throughout your document
thermo_gap_treat <- thermo_models_list[["thermo_gap_ai_treatment_treat"]]
thermo_gap_treat_cov <- thermo_models_list[["thermo_gap_ai_treatment_cov"]]
full_thermo_gap_model <- thermo_models_list[["full_thermo_gap_ai_treatment_model"]]

thermo_ml_treat <- thermo_models_list[["thermo_ml_ai_treatment_treat"]]
thermo_ml_treat_cov <- thermo_models_list[["thermo_ml_ai_treatment_cov"]]
full_thermo_ml_model <- thermo_models_list[["full_thermo_ml_ai_treatment_model"]]

thermo_ll_treat <- thermo_models_list[["thermo_ll_ai_treatment_treat"]]
thermo_ll_treat_cov <- thermo_models_list[["thermo_ll_ai_treatment_cov"]]
full_thermo_ll_model <- thermo_models_list[["full_thermo_ll_ai_treatment_model"]]
```

```{r save-thermo-gap-table, echo=FALSE, warning=FALSE, message=FALSE}
source("../analysis/thermo_models.R")
save_thermo_table(
    file = "../outputs/tables/thermo_gap_ai_results.tex",
    treat = thermo_gap_treat,
    cov = thermo_gap_treat_cov,
    full = full_thermo_gap_model,
    coef_omit = "^(age|political_attention|profile_gender|education_recode|profile_work_stat|pastvote_ge_2024|pastvote_EURef|profile_GOR)",
    coef_rename = c(
        "ai_treatment" = "AI Treatment",
        "political_attention" = "Political Attention",
        "education_recode" = "Education"
    ),
    title = "AI-Generated Content: Thermometer Gap Results \\label{tab:thermo-results}",
    notes = "Note: Models weighted using YouGov survey weights. The coefficients are reported with robust standard errors in parentheses. Main effects of the included moderators are also reported as rows above the moderator treatment effects.",
    add_rows = tibble::tibble(
        term = "Model",
        `Treatment Only` = "(1)",
        `Treatment + Covariates` = "(2)",
        `Full Model` = "(3)"
    )
)
```

\input{../outputs/tables/thermo_gap_ai_results.tex}

The primary takeaway from model (3) in \hyperref[tab:thermo-results]{Table \ref*{tab:thermo-results}} is that there is no significant treatment effect seen for the exposure to AI-generated content on the reported net-difference thermometer scores. The treatment group shows a slight decrease of **``r paste0(round(coef(summary(full_thermo_gap_model))["ai_treatment", "Estimate"], 3), " points")``** in the thermometer gap, but this is not statistically significant. However, reposndents who were most likely to vote for the Liberal Democrats showed a significant increase of **``r paste0(round(coef(summary(full_thermo_gap_model))["mostlikelyLiberal Democrats", "Estimate"], 3), " points")``** at the 95% confidence level in their net-difference thermometer gap, compared to those who were most likely to vote for the Conservative Party. This implies that Liberal Democrat voters are more susceptible to being polarised against their opposing partisans when exposed to AI-generated content. The effect size is notable too. The total treatment effect of AI exposure for Liberal Democrat voters on their affective polarisation is **``r paste0(round(coef(summary(full_thermo_gap_model))["ai_treatment", "Estimate"], 3), " + ", round(coef(summary(full_thermo_gap_model))["mostlikelyLiberal Democrats", "Estimate"], 3), " = ", round(coef(summary(full_thermo_gap_model))["ai_treatment", "Estimate"] + coef(summary(full_thermo_gap_model))["mostlikelyLiberal Democrats", "Estimate"], 3), " points")``**. This is a significant effect size, and suggests that AI-generated content can have a polarising effect. Other than Liberal Democrat voters, the full model suggests that the treatment of exposure to AI-generated content does not have a significant differential effect on the thermometer gap for different sub-groups of respondents.

To test what drives this affective polarisation, the models for the outcome variables of `MLthermoMean` and `LLthermoMean` are estimated. These models are presented in the Appendix in \hyperref[tab:thermo-ml-results]{Table \ref*{tab:thermo-ml-results}} and \hyperref[tab:thermo-ll-results]{Table \ref*{tab:thermo-ll-results}}. Thermometer scores for both in- and out-party leaders show positive increases of **``r paste0(round(coef(summary(full_thermo_ml_model))["ai_treatment", "Estimate"], 3), " points")``** and **``r paste0(round(coef(summary(full_thermo_ll_model))["ai_treatment", "Estimate"], 3), " points")``** respectively to the treatment but the scores are not statistically significant. These models do not show any sub-group differences from moderator variables.

```{r thermo_models_ai_plot, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# Source required functions and models
source("../analysis/thermo_models_plots.R")
source("../analysis/thermo_models.R")

# Define the models to include
models_ai <- list(
    ML = full_thermo_ml_model,
    LL = full_thermo_ll_model,
    GAP = full_thermo_gap_model
)

# Define the subgroups for plotting
subgroups_ai <- list(
    Overall = list(
        name = "Average Treatment Effect",
        interaction_terms = NULL
    ),
    LibDem = list(
        name = "Liberal Democrat Subgroup",
        interaction_terms = c(
            ML = "ai_treatment:mostlikelyLiberal Democrats",
            LL = "ai_treatment:mostlikelyLiberal Democrats",
            GAP = "ai_treatment:mostlikelyLiberal Democrats"
        )
    ),
    Green = list(
        name = "Green Party Subgroup",
        interaction_terms = c(
            ML = "ai_treatment:mostlikelyGreen Party",
            LL = "ai_treatment:mostlikelyGreen Party",
            GAP = "ai_treatment:mostlikelyGreen Party"
        )
    ),
    LowEdu = list(
        name = "Low Education Subgroup",
        interaction_terms = c(
            ML = "ai_treatment:education_recodeLow",
            LL = "ai_treatment:education_recodeLow",
            GAP = "ai_treatment:education_recodeLow"
        )
    )
)

# Generate and save the patchwork plot
plot_thermo_patchwork(
    models = models_ai,
    treatment_var = "ai_treatment",
    subgroups = subgroups_ai,
    output_file = "../outputs/figures/thermo_patchwork_ai_treatment.pdf"
)
```

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../outputs/figures/thermo_patchwork_ai_treatment.pdf}
    \caption{Thermometer Score Patchwork Plot for AI-Generated Content}
    \label{fig:thermo-patchwork-ai}
\end{figure}


### Ordinal Affective Polarisation Analysis {#sec-ordinal-analysis}

To further disect the affective polarisation caused by treatment to AI-generated content, models for the outcome variables of `agreedisagree`, `xtrust`, and `child` are next estimated. These models are ordinal logistic regression models, as the outcome variables are ordinal measures. The results of these models for each measure of respect, trust, and social-distance to opposing partisans are presented in \hyperref[tab:agreedisagree-results]{Table \ref*{tab:agreedisagree-results}}, \hyperref[tab:xtrust-results]{Table \ref*{tab:xtrust-results}}, and \hyperref[tab:child-results]{Table \ref*{tab:child-results}} respectively.

```{r fit-ai-ordinal-models, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
source("../analysis/ordinal_models.R")

agreedisagree_ai_treat <- readRDS("../outputs/models/agreedisagree_ai_treatment_treat.rds")
agreedisagree_ai_cov <- readRDS("../outputs/models/agreedisagree_ai_treatment_cov.rds")
full_agreedisagree_ai_model <- readRDS("../outputs/models/full_agreedisagree_ai_treatment_model.rds")

xtrust_ai_treat <- readRDS("../outputs/models/xtrust_ai_treatment_treat.rds")
xtrust_ai_cov <- readRDS("../outputs/models/xtrust_ai_treatment_cov.rds")
full_xtrust_ai_model <- readRDS("../outputs/models/full_xtrust_ai_treatment_model.rds")

child_ai_treat <- readRDS("../outputs/models/child_ai_treatment_treat.rds")
child_ai_cov <- readRDS("../outputs/models/child_ai_treatment_cov.rds")
full_child_ai_model <- readRDS("../outputs/models/full_child_ai_treatment_model.rds")
```

```{r ai-ordinal-plots, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
source("../analysis/ordinal_models_plots.R")
# Generate the plots for each significant subgroup to plot
plot_disagreement <- generate_plot_for_outcome(
    data = yougov_data,
    outcome = "agreedisagree",
    treatment = "ai_treatment",
    moderators = moderators_agreedisagree,
    covariates = covariates_agreedisagree,
    moderator_terms = moderator_terms_agreedisagree,
    collapse_levels = c("Strongly disagree", "Tend to disagree"),
    moderator_labels = moderator_labels_agreedisagree,
    plot_title = "Do not Respect Beliefs (AI Treatment)"
)

plot_trust <- generate_plot_for_outcome(
    data = yougov_data,
    outcome = "xtrust",
    treatment = "ai_treatment",
    moderators = moderators_xtrust,
    covariates = covariates_xtrust,
    moderator_terms = moderator_terms_trust,
    collapse_levels = c("Almost never", "Once in a while"),
    moderator_labels = moderator_labels_trust,
    plot_title = "Do not Trust to do Right (AI Treatment)"
)

plot_discomfort <- generate_plot_for_outcome(
    data = yougov_data,
    outcome = "child",
    treatment = "ai_treatment",
    moderators = moderators_child,
    covariates = covariates_child,
    moderator_terms = moderator_terms_child,
    collapse_levels = c("Extremely upset", "Somewhat upset"),
    moderator_labels = moderator_labels_child,
    plot_title = "Discomfort with Marrying Out-Group (AI Treatment)"
)

# Combine plots with patchwork
library(patchwork)
combined_plot <- plot_disagreement + plot_trust + plot_discomfort +
    plot_layout(ncol = 3, guides = "collect") &
    theme(legend.position = "bottom")

ggsave(
    filename = "../outputs/figures/ordinal_patchwork_ai_treatment.pdf",
    plot = combined_plot,
    width = 10, height = 4
)
```

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{../outputs/figures/ordinal_patchwork_ai_treatment.pdf}
    \caption{Ordinal Affective Polarisation Patchwork Plot for AI-Generated Content}
    \label{fig:ordinal-patchwork-ai}
\end{figure}

## AI-Labelled Content Treatment {#sec-label-treatment}

### Thermometer Analysis {#sec-label-thermo-analysis}

### Ordinal Affective Polarisation Analysis {#sec-label-ordinal-analysis}

## Additional Analysis

### Causal Acyclic Testing

(see exeprimental analysis week 6 notes for details)

### Agentic-based Modelling
- What is agentic-based modelling?
- Why is agentic-based modelling important?
- How will I use agentic-based modelling?


\newpage
\addtocontents{toc}{\protect\setcounter{tocdepth}{1}}

# Appendix {-}

## Codebook {#sec-codebook}

The codebook in \hyperref[tab:codebook-table]{Table \ref*{tab:codebook-table}} below provides a summary of the variables used in the YouGov UniOM analysis. The variable names are provided in the first column, followed by the type of variable (e.g., categorical, continuous), a description of the variable, and the values that the variable can take. Note that the outcome variables of `agreedisagree`, `xtrust`, and `child` are ordinal variables on an ordered Likert scale.

```{r codebook-table, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
source("../analysis/codebook.R")
cat(create_codebook_table())
```


\newpage

## Data Cleaning

`2,001` respondents were provided with the survey experiment. Respondents who did not give consent to participate in the survey were removed. Respondents were given the option to skip questions. When skipped, a value of `997` was assigned to the question, which was then recoded to `NA`, as were `Not asked` values.

The survey was interested in understanding respondents' views towards their most and least preferred party. When asked who the `mostlikely` and `leastlikely` party was, respondents were given the option to select `None of these`. Respondents who selected `None of these` were removed from the sample as they were unable to answer the follow-up questions.

Categorical variables were recoded to be `factors` in R, these were `profile_gender`, `profile_GOR`, `voted_ge_2024`, `pastvote_ge_2024`, `pastvote_EURef`, `profile_education_level`, `education_recode`, `profile_work_stat`, `xconsent`, `mostlikely`, `leastlikely`, `agreedisagree`, `xtrust`, and `child`.

Each of the thermometer variables were recoded to be `numeric` variables: `MLthermo_KB`, `MLthermo_KS`, `MLthermo_NF`, `MLthermo_ED`, `MLthermo_CD`, `MLthermo_AR`, `LLthermo_KB`, `LLthermo_KS`, `LLthermo_NF`, `LLthermo_ED`, `LLthermo_CD`, and `LLthermo_AR`. As the Green Party has two co-leaders, a mean thermometer score is calculated and used for most and least likely party thermometer scores, coded as `MLthermoMean` and `LLthermoMean`.

For treatment effect analysis, respondents were classified into two treatment groups: those shown AI-generated content (`ai_treatment`), identified where the split variable equalled `1` or `2`; and those shown AI-labelled content (`label_treatment`), identified where the split variable equalled `2` or `3`. Participants in the other split groups were coded as receiving human-generated or unlabelled content. These variables were coded as binary variables, where `1` indicated the treatment group and `0` indicated the control group.


## Balance Check {#sec-balance}

To ensure that the randomisation process of the treatment allocation was successful, a balance check is conducted to ensure that the treatment and control groups are comparable in every way other than their treatment assignment status. \hyperref[tab:ai-balance]{Table \ref*{tab:ai-balance}} and \hyperref[tab:label-balance]{Table \ref*{tab:label-balance}} below report the balance of the covariates across the treatment groups. The continuous variables of `age` and `political_attention` are reported as means with the standard deviations in parentheses. The remaining categorical variables are reported as a count from the sample, with the proportions in parentheses. If there was a significant difference between the treatment and control groups, this is indicated with a `*` for p < 0.05, `**` for p < 0.01, and `***` for p < 0.001. The balance check shows that randomisation was successful across all covariates for both treatment groups as no covariates were significantly different between the treatment and control groups.

Note that the p-values are reported at the variable level, not for each individual category within a categorical variable. For categorical variables (e.g., gender, vote choice), a single p-value is generated using a chi-squared test, which assesses whether the overall distribution of categories differs between treatment and control groups. The individual category rows are displayed for reference, but since the test is run at the variable level, no p-value is reported for each specific level, giving the `NA` values in the tables.

For each of the categorical variables, there is a base reference category. For example, `profile_gender` uses the base reference category `Male` (reported as `Gender (Male)` in the balance tables). This base acts as the comparison group for the other categories, the p-value compares whether the distribution of the other categories is significantly different from the base category.

```{r ai-balance, echo=FALSE, message=FALSE, results='asis'}
source("../analysis/balance_analysis.R")
```

## Sensitivity Analysis

Given the nature of the results often being reported as null effects, a sensitivity analysis to determine what the smallest true effect that could have detected 80% of the time is calculated.

```{r Sensitivity Analysis, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# === Sensitivity Analysis ===
```

## `MLthermoMean` and `LLthermoMean` Analysis {#sec-MLthermo}

The models for the outcome variables of `MLthermoMean` and `LLthermoMean` are estimated using the same model specification as for `thermo_gap` in \hyperref[tab:thermo-results]{Table \ref*{tab:thermo-results}}. These models are presented in \hyperref[tab:thermo-ml-results]{Table \ref*{tab:thermo-ml-results}} and \hyperref[tab:thermo-ll-results]{Table \ref*{tab:thermo-ll-results}} respectvely.

```{r save-thermo-ml-table, echo=FALSE, warning=FALSE, message=FALSE}
source("../analysis/thermo_models.R")
save_thermo_table(
    file = "../outputs/tables/thermo_ml_ai_results.tex",
    treat = thermo_ml_treat,
    cov = thermo_ml_treat_cov,
    full = full_thermo_ml_model,
    coef_omit = "^(political_attention|profile_gender|education_recode|profile_work_stat|pastvote_ge_2024|pastvote_EURef|profile_GOR)",
    coef_rename = c(
        "ai_treatment" = "AI Treatment",
        "age" = "Age",
        "education_recode" = "Education"
    ),
    title = "AI-Generated Content: Thermometer (mostlikely) Results \\label{tab:thermo-ml-results}",
    notes = "Note: Models weighted using YouGov survey weights. The coefficients are reported with robust standard errors in parentheses. Main effects of the included moderators are also reported as rows above the moderator treatment effects.",
    add_rows = tibble::tibble(
        term = "Model",
        `Treatment Only` = "(1)",
        `Treatment + Covariates` = "(2)",
        `Full Model` = "(3)"
    )
)
```

```{r save-thermo-ll-table, echo=FALSE, warning=FALSE, message=FALSE}
source("../analysis/thermo_models.R")
save_thermo_table(
    file = "../outputs/tables/thermo_ll_ai_results.tex",
    treat = thermo_ll_treat,
    cov = thermo_ll_treat_cov,
    full = full_thermo_ll_model,
    coef_omit = "^(age|political_attention|profile_gender|education_recode|profile_work_stat|pastvote_ge_2024|profile_GOR|pastvote_EURef)",
    coef_rename = c(
        "ai_treatment" = "AI Treatment",
        "pastvote_EURef" = "EURef Vote",
        "education_recode" = "Education"
    ),
    title = "AI-Generated Content: Thermometer (leastlikely) Results \\label{tab:thermo-ll-results}",
    notes = "Note: Models weighted using YouGov survey weights. The coefficients are reported with robust standard errors in parentheses. Main effects of the included moderators are also reported as rows above the moderator treatment effects.",
    add_rows = tibble::tibble(
        term = "Model",
        `Treatment Only` = "(1)",
        `Treatment + Covariates` = "(2)",
        `Full Model` = "(3)"
    )
)
```

\input{../outputs/tables/thermo_ml_ai_results.tex}
\input{../outputs/tables/thermo_ll_ai_results.tex}

## Ordinal Affective Polarisation Results {#sec-ordinal-results}

The following results presented in \hyperref[tab:agreedisagree-results]{Table \ref*{tab:agreedisagree-results}}, \hyperref[tab:xtrust-results]{Table \ref*{tab:xtrust-results}}, and \hyperref[tab:child-results]{Table \ref*{tab:child-results}} show the log-odds change in the probability of being in a higher level (a higher threshold cut point) of agreement, trust, or comfort respectively.

```{r ordinal-tables, echo=FALSE, message=FALSE, results='asis'}
source("../analysis/ordinal_models.R")
save_ordinal_table(
    file = "../outputs/tables/agreedisagree_ai_results.tex",
    treat = agreedisagree_ai_treat,
    cov = agreedisagree_ai_cov,
    full = full_agreedisagree_ai_model,
    coef_omit = "^(age|political_attention|profile_gender|education_recode|profile_work_stat)",
    coef_rename = c(
        "ai_treatment" = "AI Treatment",
        "education_recodeLow" = "Low Education",
        "education_recodeMedium" = "Medium Education",
        "profile_work_statNot working" = "Not Working",
        "profile_work_statOther" = "Other",
        "profile_work_statRetired" = "Retired",
        "profile_work_statUnemployed" = "Unemployed",
        "profile_work_statWorking full time (30 or more hours per week)" = "Working Full Time",
        "profile_work_statWorking part time (8-29 hours a week)" = "Working PT (8–29h)",
        "profile_work_statWorking part time (Less than 8 hours a week)" = "Working PT (<8h)",
        "ai_treatment:education_recodeLow" = "AI Treatment:Low Education",
        "ai_treatment:education_recodeMedium" = "AI Treatment:Medium Education",
        "ai_treatment:profile_work_statNot working" = "AI Treatment:Not Working",
        "ai_treatment:profile_work_statOther" = "AI Treatment:Other",
        "ai_treatment:profile_work_statRetired" = "AI Treatment:Retired",
        "ai_treatment:profile_work_statUnemployed" = "AI Treatment:Unemployed",
        "ai_treatment:profile_work_statWorking full time (30 or more hours per week)" = "AI Treatment:Working Full Time",
        "ai_treatment:profile_work_statWorking part time (8-29 hours a week)" = "AI Treatment:Working PT (8–29h)",
        "ai_treatment:profile_work_statWorking part time (Less than 8 hours a week)" = "AI Treatment:Working PT (<8h)"
    ),
    title = "AI-Generated Content: Agree Out-Party Respect Beliefs \\label{tab:agreedisagree-results}",
    notes = "Note: Ordered logistic regression with survey weights and robust standard errors in parentheses. Coefficients represent log-odds of agreement that opposing partisans respect political beliefs. Threshold cutpoints are included but have no substantive interpretation.",
    add_rows = tibble::tibble(
        term = "Model",
        `Treatment Only` = "(1)",
        `Treatment + Covariates` = "(2)",
        `Full Model` = "(3)"
    )
)

save_ordinal_table(
    file = "../outputs/tables/xtrust_ai_results.tex",
    treat = xtrust_ai_treat,
    cov = xtrust_ai_cov,
    full = full_xtrust_ai_model,
    coef_omit = "^(age|political_attention|profile_gender|education_recode|profile_work_stat|pastvote_ge_2024|pastvote_EURef|profile_GOR)",
    coef_rename = c(
        "ai_treatment" = "AI Treatment",
        "education_recode" = "Education"
    ),
    title = "AI-Generated Content: Trust in Out-Party to Do What Is Right \\label{tab:xtrust-results}",
    notes = "Note: Ordered logistic regression with survey weights and robust standard errors in parentheses. Coefficients represent log-odds of trusting that opposing parties will do what is right for the country. Threshold cutpoints are included but have no substantive interpretation.",
    add_rows = tibble::tibble(
        term = "Model",
        `Treatment Only` = "(1)",
        `Treatment + Covariates` = "(2)",
        `Full Model` = "(3)"
    )
)

save_ordinal_table(
    file = "../outputs/tables/child_ai_results.tex",
    treat = child_ai_treat,
    cov = child_ai_cov,
    full = full_child_ai_model,
    coef_omit = "^(?!(ai_treatment(:|$))).*|\\|",
    coef_rename = c(
        "ai_treatment" = "AI Treatment",
        "education_recode" = "Education Level",
        "profile_GOR" = "Region"
    ),
    title = "AI-Generated Content: Comfort with Child Marrying Opposing Partisan \\label{tab:child-results}",
    notes = "Note: Ordered logistic regression with survey weights and robust standard errors in parentheses. Coefficients represent log-odds of comfort with a child marrying an opposing party voter. Threshold cutpoints are included but have no substantive interpretation.",
    add_rows = tibble::tibble(
        term = "Model",
        `Treatment Only` = "(1)",
        `Treatment + Covariates` = "(2)",
        `Full Model` = "(3)"
    )
)
```

\input{../outputs/tables/agreedisagree_ai_results.tex}
\input{../outputs/tables/xtrust_ai_results.tex}
\input{../outputs/tables/child_ai_results.tex}

\newpage

# Bibliography