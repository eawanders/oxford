---
title: "MPhil Politics, Comparative Government"
author: "Edward Anders"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
    pdf_document:
        fig_width: 6
        fig_height: 4
        fig_caption: true
        toc: true
        toc_depth: 2
        number_sections: true
    includes:
        in_header: header.tex
documentclass: article
zotero: true
link-citations: true
csl: /Users/edwardanders/Documents/GitHub/oxford/metadata/harvard-cite-them-right.csl
bibliography: /Users/edwardanders/Documents/GitHub/oxford/metadata/zotero_library.bib
header-includes:
  - \usepackage{setspace}
  - \setstretch{1.5}
  - \usepackage[para]{threeparttable}
  - \usepackage[margin=1in]{geometry}
  - \setlength{\footnotesep}{1em}
  - \setlength{\skip\footins}{2em}
---

```{r Data Setup, include=FALSE}
# The data is from a survey conducted by YouGov  
# === R Script Setup ===

# Load necessary packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) {
    install.packages("pacman")
}

pacman::p_load(
    tidyverse,
    haven,
    MASS,
    dplyr,
    emmeans,
    ggplot2,
    tableone,
    survey,
    kableExtra,
    stringr,
    purrr,
    tibble
)

# === Data Import and Review ===

# Load .csv file into R
yougov_data <- read_csv(
    "/Users/edwardanders/Documents/GitHub/oxford/thesis/data/yougov/uniom_results.csv"
)

# View summary of the data
summary(yougov_data)
str(yougov_data)
glimpse(yougov_data)


# === Data Cleaning and Transformation ===

# Check for missing values
## The only missing values are found in pastvote_ge_2024
## But these are as a result of voted_ge_2024 being
## 'No, did not vote' or 'Don't know'
missing_values <- sapply(yougov_data, function(x) sum(is.na(x)))

# Remove columns that are not needed
yougov_data <- yougov_data %>%
    dplyr::select(-c(
        randMOSTLEAST,
        MLthermo,
        LLthermo
    ))

# Convert any values == 'Not asked' to NA
yougov_data <- yougov_data %>%
    mutate(across(where(is.character), ~ na_if(., "Not asked")))

# Convert any values == '997' to NA
yougov_data <- yougov_data %>%
    mutate(across(where(is.character), ~ na_if(., "997")))

# Convert character columns to factors
yougov_data <- yougov_data %>%
    mutate(across(c(
        profile_gender,
        profile_GOR,
        voted_ge_2024,
        pastvote_ge_2024,
        pastvote_EURef,
        profile_education_level,
        profile_education_level_recode,
        profile_work_stat,
        xconsent,
        mostlikely,
        leastlikely,
        agreedisagree,
        xtrust,
        child,
    ), as.factor))

# Convert relevant columns to numeric
yougov_data <- yougov_data %>%
    mutate(across(c(
        MLthermo_KB,
        MLthermo_KS,
        MLthermo_NF,
        MLthermo_ED,
        MLthermo_CD,
        MLthermo_AR,
        LLthermo_KB,
        LLthermo_KS,
        LLthermo_NF,
        LLthermo_ED,
        LLthermo_CD,
        LLthermo_AR
    ), ~ as.numeric(as.character(.))))

# Remove rows where 'xconsent == I do not with to continue with this study'
yougov_data <- yougov_data %>%
    filter(xconsent != "I do not wish to continue with this study")


# Create new MLthermo and LLthermo mean variables
# Variable is mean of values in MLthermo/LLthermo columns
yougov_data <- yougov_data %>%
    mutate(
        MLthermoMean = rowMeans(pick(starts_with("MLthermo_")), na.rm = TRUE),
        LLthermoMean = rowMeans(pick(starts_with("LLthermo_")), na.rm = TRUE)
    )

# Remove rows where 'mostlikely == None of these'
# and 'leastlikely == None of these'
yougov_data <- yougov_data %>%
    filter(mostlikely != "None of these" & leastlikely != "None of these")


# Create a new treatment status variable for AI-generated content
## Where treatment == 1, the respondent was shown AI-generated content
## Where treatment == 0, the respondent was shown human-generated content
## When 'split == 1 or 2', the respondent was shown AI-generated content
yougov_data <- yougov_data %>%
    mutate(ai_treatment = case_when(
        split == 1 ~ 1,
        split == 2 ~ 1,
        split == 3 ~ 0,
        split == 4 ~ 0,
        TRUE ~ NA_real_
    ))

# Create a new treatment status variable for AI-labelled content
## Where treatment == 1, respondents shown content labelled as AI-generated
## Where treatment == 0, respondents shown content labelled as human-generated
## When 'split == 2 or 3', the respondent was shown AI-labelled content
yougov_data <- yougov_data %>%
    mutate(label_treatment = case_when(
        split == 2 ~ 1,
        split == 3 ~ 1,
        split == 1 ~ 0,
        split == 4 ~ 0,
        TRUE ~ NA_real_
    ))

# Refactor child variable
yougov_data <- yougov_data %>%
    mutate(child = na_if(child, "Don't know")) %>%
    mutate(child = na_if(child, "Not Asked"))

yougov_data <- yougov_data %>%
    mutate(child = factor(child,
        levels = c(
            "Extremely upset",
            "Somewhat upset",
            "Neither happy nor upset",
            "Somewhat happy",
            "Extremely happy"
        ),
        ordered = TRUE
    ))

# Refactor xtrust variable
yougov_data <- yougov_data %>%
    mutate(xtrust = na_if(xtrust, "Don't know"))

yougov_data <- yougov_data %>%
    mutate(xtrust = factor(xtrust,
        levels = c(
            "Almost never",
            "Once in a while",
            "About half of the time",
            "Always",
            "Most of the time"
        ),
        ordered = TRUE
    ))

# Refactor agreedisagree variable
yougov_data <- yougov_data %>%
    mutate(agreedisagree = na_if(agreedisagree, "Don't know"))

yougov_data <- yougov_data %>%
    mutate(agreedisagree = factor(agreedisagree,
        levels = c(
            "Strongly disagree",
            "Tend to disagree",
            "Neither agree nor disagree",
            "Tend to agree",
            "Strongly agree"
        ),
        ordered = TRUE
    ))

# Rename profile_education_level_recode
yougov_data <- yougov_data %>%
    rename(
        education_recode = profile_education_level_recode
    )

# Drop levels from `mostlikely` that have no observations
yougov_data$mostlikely <- droplevels(
    yougov_data$mostlikely
)

# Create a new `thermo_gap` variable for the difference between MLthermo and LLthermo
yougov_data <- yougov_data %>%
    mutate(thermo_gap = MLthermoMean - LLthermoMean)
```

\newpage

# Case selection and data gathering

- See pre-analysis plan for details of what to include in this section
- Case selection (why focus on the UK?)
    - I am to have external validity to my research/case?
    - Can I make inferences to other cases?
- What is the case?
    - What is the unit of analysis?
    - What is the time period?
    - What is the geographical scope?
    - What are the key variables?
- What data is being collected?
- How is the data being collected?
    - What is the sampling strategy?
    - Note the UK weighting

- Plan for using agentic modelling
    - Why would I use agentic modelling?
    - What is the agentic modelling?
    - How will I use agentic modelling?

- Note the use of a between-subjects survey experiment
    - Deliberately chosen to avoid sensitivity issues noted by @levendusky2021

# Data analysis

The following data analyses focus on all outcome measures of affective polarisation to give a holistic understading of both general and tangible prejudices and discriminatory behaviours towards the opposing out-group to that of the respondent's identified in-group. The analysis covers all outcome measures across of the causal effects of both the aforementioned treatment groups of AI-generated and AI-labelled content.

## Outcome Measures

The measures required to understand AI's affect on affective polarisation are multi-faceted. Different measures can be used to understand the primary outcome of affective polarisation; however, the implication of each measure differs. @druckman2019 clearly outline the best practices for these affective polarisation measures, and how the measures interact. Therefore, this research chooses to follow these measurement recommendations for use in survey self-reporting [@iyengar2019].

The most common measure of someone's identifiction with a political party is through a feeling thermometer score. This aims to understand how warmly or coldly someone feels towards the political parties they most and leat prefer. The thermometer scores are measured on a scale of `0` to `100`, where `0` is the coldest and `100` is the warmest.[^1] This survey experiment firstly asks respondents to identify their most and least preferred party (`mostlikely` and `leastlikely`), allowing for in- and out-party identities to be exposed. We then ask respondents to firstly rate how warmly they feel towards each of these party's leaders, `MLthermo_XY` and `LLthermo_XY`, where `XY` is replaced by each party leader's initials. The use of party-leader thermometers is a common measure, leaning on valence theory's emphasis on the importance of party leaders in shaping party identification and voting behaviour [@garzia2023].[^2] Moreover, Druckman and Levendusky's (2019: 119) findings show that respondents are more  negative towards party elites rather than party voters; thus, the focus on party leaders here helps elicit the more visceral feelings. Alongside these in- and out-group measures, a net-difference score (`thermo_gap`) is also calculated as the difference between the thermometer scores (`MLthermoMean - LLthermoMean`) [@iyengar2012].

The next indicator of affective polarisation is a trait-based rating. This measure identifies the traits that respondents associate with opposing parties [@garrett2014]. The limited scope of the survey experiment meant we focussed on the trait of positive trait of *respect*, and whether respondents associated this trait with oppossing parties. Respondents were asked: "To what extent do you agree or disagree with the following statement: `[leastlikely]` party voters respect my political beliefs and opinions." This question — coded as `agreedisagree` — was asked in a Likert scale format of levels of agreement.[^3]

Additionally, a similar trait-based measure focussed on *trust* was used [@levendusky2013]. Here, we ask "And how much of the time do you think you can trust `[leastlikely]` party to do what is right for the country?". This question was also asked in a Likert scale format, with the options of `Almost never`, `Once in a while`, `About half of the time`, `Most of the time`, and `Always`. This measure is coded as `xtrust`. Along with the themometer score, the trait-based views of respect, and trust in opposing parties, Druckman and Levendusky (2019: 119) argue that these measures are good, general measures of prejudices held towards opposing parties.

On the other hand, affective polarisation should also be interested in actual tangible discriminatory behaviour. Therefore a social-distance-based question is included to understand how comfortable respondents are with having opposing partisans in their lives. For example, @iyengar2012 popularised the use of the @almond1963 five-nation survey question "Suppose you had a child who was getting married. How would you feel if they married a `[leastlikely]` party voter?". Coded as `child`, respondents were given options of `Extremely upset`, `Somewhat upset`, `Neither happy nor upset`, `Somewhat happy`, and `Extremely happy`.

[^1]: The wording for the theremoeter score questions is as follows: "We’d like to get your feelings toward some of our political leaders and other groups who are in the news these days. On the next page, we’ll ask you to do that using a 0 to 100 scale that we call a feeling thermometer. Ratings between 50 degrees and 100 degrees mean that you feel favourable and warm toward the person. Ratings between 0 degrees and 50 degrees mean that you don't feel favourable toward the person and that you don't care too much for that person. You would rate the person at the 50-degree mark if you don't feel particularly warm or cold toward the person."
[^2]: The Green Party has two co-leaders, Carla Denyer and Adrian Ramsay. Therefore, ratings of both leaders are asked, and the thermometer scores for the Green Party are averaged to create a single score for the party. The variables `MLthermoMean` and `LLthermoMean` are used as the final thermometer measures for in- and out-group thermometer scores.
[^3]: A full breakdown of the survey experiment variables and values can be found in the codebook in the appendix.

## Thermometer Analysis

The thermometer scores are continuous measures. We present results from the survey experiment for in- and out-group scores, as well as the net-difference score. A brief summary of the average `thermo_gap` measures across treatments is prsented below. This indicates an initial view of how minimal the treatment effects are.

```{r Descriptive Thermometer Graph, echo=FALSE, message=FALSE, results='asis', fig.width=5, fig.height=3, fig.align='center', fig.cap = "Average in- and out-party thermometer net-difference scores"}
# === Descriptive Thermometer Graph ===


# Reshaped data to long format
thermo_data <- yougov_data %>%
    dplyr::select(thermo_gap, ai_treatment, label_treatment) %>%
    pivot_longer(
        cols = c(ai_treatment, label_treatment),
        names_to = "treatment_type",
        values_to = "treated"
    ) %>%
    filter(!is.na(treated), !is.na(thermo_gap)) %>%
    mutate(
        treatment_type = recode(treatment_type,
            "ai_treatment" = "AI treatment",
            "label_treatment" = "Label Treatment"
        ),
        treated = factor(treated, levels = c(0, 1), labels = c("Control", "Treatment"))
    )

# Group means
summary_stats <- thermo_data %>%
    group_by(treatment_type, treated) %>%
    summarise(
        mean_gap = mean(thermo_gap, na.rm = TRUE),
        .groups = "drop"
    )

# Ggplot of results
ggplot(summary_stats, aes(x = treatment_type, y = mean_gap, fill = treated)) +
    geom_col(position = position_dodge(width = 0.7), width = 0.6) +
    labs(
        x = NULL,
        y = "Average Thermometer Gap",
        fill = "Group"
    ) +
    scale_fill_manual(
        labels = c("Control", "Treatment"),
        values = c("#bdbdbd", "#4b4b4b")
    ) +
    ylim(0, NA) +
    theme_classic(base_family = "serif") +
    theme(
        axis.title.x = element_text(size = 10, margin = margin(t = 10)),
        axis.title.y = element_text(size = 10, margin = margin(r = 10)),
        axis.text = element_text(size = 9),
        legend.title = element_text(size = 9),
        legend.text = element_text(size = 9)
    )
```

To understand the treatment effects on the thermometer scores, we run a series of linear regression models. The models are run with the following specifications:

### Moderator Heterogeneity Analysis

## Outcome Variable Analysis

### Moderator Heterogeneity Analysis

## Additional Analysis

### Causal Acyclic Testing

(see exeprimental analysis week 6 notes for details)

### Agentic-based Modelling
- What is agentic-based modelling?
- Why is agentic-based modelling important?
- How will I use agentic-based modelling?


\newpage


# Appendix

## Codebook

The codebook below provides a summary of the variables used in the YouGov UniOM analysis. The variable names are provided in the first column, followed by the type of variable (e.g., categorical, continuous), a description of the variable, and the values that the variable can take. Note that the outcome variables of `agreedisagree`, `xtrust`, and `child` are ordinal variables on an ordered Likert scale.

```{r Codebook Table, echo=FALSE, results='asis', message=FALSE, warning=FALSE}
# === Codebook ===
# Input variable names as plain text (no LaTeX yet)

codebook <- tribble(
    ~Variable, ~Type, ~Description, ~Values,
    "identity_client", "Identifier", "Unique identifier for the respondent", "Alphanumeric string",
    "weight", "Continuous", "Survey weight to ensure national representativeness", "Continuous float (e.g., 0.982, 1.034)",
    "age", "Continuous", "Age of the respondent", "Integer values, typically 18–90",
    "profile_gender", "Categorical", "Gender of the respondent", "Female; Male",
    "profile_GOR", "Categorical", "Government Office Region (region of residence)", "East Midlands; East of England; London; North East; North West; Scotland; South East; South West; Wales; West Midlands; Yorkshire and the Humber",
    "voted_ge_2024", "Categorical", "Did the respondent vote in the 2024 General Election?", "Don’t know; No, did not vote; Yes, voted",
    "pastvote_ge_2024", "Categorical", "How the respondent voted in the 2024 General Election", "Conservative; Don't know; Green; Labour; Liberal Democrat; Other; Plaid Cymru; Reform UK; Scottish National Party (SNP); Skipped",
    "pastvote_EURef", "Categorical", "How the respondent voted in the 2016 EU Referendum", "Can’t remember; I did not vote; I voted to Leave; I voted to Remain",
    "education_recode", "Categorical", "Re-coded education level (grouped)", "High; Medium; Low",
    "profile_work_stat", "Categorical", "Employment status", "Full time student; Not working; Other; Retired; Unemployed; Working full time (30+ hrs); Working part time (8–29 hrs); Working part time (<8 hrs)",
    "political_attention", "Continuous", "How much attention the respondent pays to politics", "Scale (e.g., 0–10 or continuous values)",
    "split", "Categorical", "Randomly assigned treatment group (1–4)", "1 = AI-generated, not labelled as AI-generated; 2 = AI-generated and labelled as AI-generated; 3 = Human-generated but labelled as AI-generated; 4 = Human-generated, not labelled as AI-generated",
    "xconsent", "Categorical", "Consent to participate in the survey", "I consent to taking part in this study; I do not wish to continue with this study",
    "mostlikely", "Categorical", "Most likely party to receive vote", "Conservative Party; Green Party; Labour Party; Liberal Democrats; Reform UK",
    "leastlikely", "Categorical", "Least likely party to receive vote", "Conservative Party; Green Party; Labour Party; Liberal Democrats; Reform UK; None of these; Not Asked",
    "MLthermo_KB", "Continuous", "Thermometer rating for Kemi Badenoch (most likely party)", "0–100",
    "MLthermo_KS", "Continuous", "Thermometer rating for Keir Starmer", "0–100",
    "MLthermo_NF", "Continuous", "Thermometer rating for Nigel Farage", "0–100",
    "MLthermo_ED", "Continuous", "Thermometer rating for Ed Davey", "0–100",
    "MLthermo_CD", "Continuous", "Thermometer rating for Carla Denyer", "0–100",
    "MLthermo_AR", "Continuous", "Thermometer rating for Adrian Ramsay", "0–100",
    "LLthermo_KB", "Continuous", "Thermometer rating for Kemi Badenoch (least likely party)", "0–100",
    "LLthermo_KS", "Continuous", "Thermometer rating for Keir Starmer", "0–100",
    "LLthermo_NF", "Continuous", "Thermometer rating for Nigel Farage", "0–100",
    "LLthermo_ED", "Continuous", "Thermometer rating for Ed Davey", "0–100",
    "LLthermo_CD", "Continuous", "Thermometer rating for Carla Denyer", "0–100",
    "LLthermo_AR", "Continuous", "Thermometer rating for Adrian Ramsay", "0–100",
    "agreedisagree", "Ordinal", "Trait-based measure of whether out-groups respect in-group beliefs ", "Strongly disagree; Tend to disagree; Neither agree nor disagree; Tend to agree; Strongly agree",
    "xtrust", "Ordinal", "Level of trust in out-group to do what is right", "Almost never; Once in a while; About half of the time; Most of the time; Always",
    "child", "Ordinal", "Social-disance measure of a child marry an out-group voter", "Extremely upset; Somewhat upset; Neither happy nor upset; Somewhat happy; Extremely happy",
    "MLthermoMean", "Continuous", "Average thermometer score for most likely party", "0–100 (row mean of MLthermo scores)",
    "LLthermoMean", "Continuous", "Average thermometer score for least likely party", "0–100 (row mean of LLthermo scores)",
    "thermo_gap", "Continuous", "Difference between MLthermoMean and LLthermoMean", "0–100 (MLthermoMean - LLthermoMean)",
    "ai_treatment", "Binary", "Treatment status for AI-generated content", "1 = Treated (shown AI-generated); 0 = Control (shown human-generated)",
    "label_treatment", "Binary", "Treatment status for AI-labelled content", "1 = Treated (labelled as AI-generated); 0 = Control (labelled as human-generated)"
)

# Format the variable names for LaTeX monospace in table cells
codebook <- codebook %>%
    mutate(Variable = paste0("\\verb|", Variable, "|"))

# Render the table
kable(codebook, format = "latex", booktabs = TRUE, longtable = TRUE, escape = FALSE, caption = "YouGov UniOM Survey Codebook") %>%
    kable_styling(
        latex_options = c("repeat_header"),
        font_size = 9
    ) %>%
    column_spec(1, width = "3.2cm") %>%
    column_spec(3, width = "5cm") %>%
    column_spec(4, width = "5cm")
```

\newpage

## Data Cleaning

`2,001` respondents were provided with the survey experiment. Respondents who did not give consent to participate in the survey were removed. Respondents were given the option to skip questions. When skipped, a value of `997` was assigned to the question, which was then recoded to `NA`, as were `Not asked` values.

The survey was interested in understanding respondents' views towards their most and least preferred party. When asked who the `mostlikely` and `leastlikely` party was, respondents were given the option to select `None of these`. Respondents who selected `None of these` were removed from the sample as they were unable to answer the follow-up questions.

Categorical variables were recoded to be `factors` in R, these were `profile_gender`, `profile_GOR`, `voted_ge_2024`, `pastvote_ge_2024`, `pastvote_EURef`, `profile_education_level`, `education_recode`, `profile_work_stat`, `xconsent`, `mostlikely`, `leastlikely`, `agreedisagree`, `xtrust`, and `child`.

Each of the thermometer variables were recoded to be `numeric` variables: `MLthermo_KB`, `MLthermo_KS`, `MLthermo_NF`, `MLthermo_ED`, `MLthermo_CD`, `MLthermo_AR`, `LLthermo_KB`, `LLthermo_KS`, `LLthermo_NF`, `LLthermo_ED`, `LLthermo_CD`, and `LLthermo_AR`. As the Green Party has two co-leaders, a mean thermometer score is calculated and used for most and least likely party thermometer scores, coded as `MLthermoMean` and `LLthermoMean`.

For treatment effect analysis, respondents were classified into two treatment groups: those shown AI-generated content (`ai_treatment`), identified where the split variable equalled `1` or `2`; and those shown AI-labelled content (`label_treatment`), identified where the split variable equalled `2` or `3`. Participants in the other split groups were coded as receiving human-generated or unlabelled content. These variables were coded as binary variables, where `1` indicated the treatment group and `0` indicated the control group.


## Balance Check

To ensure that the randomisation process of the treatment allocation was successful, a balance check is conducted to ensure that the treatment and control groups are comparable in every way other than their treatment assignment status. The tables below report the balance of the covariates across the treatment groups. The continuous variables of `age` and `political_attention` are reported as means with the standard deviations in parentheses. The remaining categorical variables are reported as a count from the sample, with the proportions in parentheses. If there was a significant difference between the treatment and control groups, this is indicated with a `*` for p < 0.05, `**` for p < 0.01, and `***` for p < 0.001. The balance check shows that randomisation was successful across all covariates for both treatment groups as no covariates were significantly different between the treatment and control groups.

Note that the p-values are reported at the variable level, not for each individual category within a categorical variable. For categorical variables (e.g., gender, vote choice), a single p-value is generated using a chi-squared test, which assesses whether the overall distribution of categories differs between treatment and control groups. The individual category rows are displayed for reference, but since the test is run at the variable level, no p-value is reported for each specific level, giving the `NA` values in the table.

For each of the categorical variables, there is a base reference category. For example, `profile_gender` uses the base reference category `Male` (reported as `Gender (Male` in the balance tables). This base acts as the comparison group for the other categories, the p-value compares whether the distribution of the other categories is significantly different from the base category.

```{r Balance Analysis, echo=FALSE, message=FALSE, results ='hide'}
# === Balance Check ===
# Check the balance of covariates across treatment groups
# to see if the randomisation was successful

# Define a reusable function for covariate balance checking
balance_table <- function(data, strata_var, covariates) {
    table <- tableone::CreateTableOne(
        vars = unlist(covariates),
        strata = strata_var,
        data = data,
        factorVars = covariates$categorical
    )
}

# Define the treatment and control groups to test balance across
treatment_vars <- c("ai_treatment", "label_treatment")

# Define the covariates for balance checking
covariates <- list(
    continuous = c("age", "political_attention"),
    categorical = c(
        "profile_gender",
        "education_recode",
        "profile_work_stat",
        "voted_ge_2024",
        "pastvote_ge_2024",
        "pastvote_EURef",
        "profile_GOR"
    )
)
# Run the balance table function for each treatment variable
for (strata_var in treatment_vars) {
    balance_table(yougov_data, strata_var, covariates)
}

# The balance check shows that randomisation was successful across
# all covariates for both treatment groups
```

```{r Balance Table Results, echo=FALSE, message=FALSE, results='asis'}
# === Balance Table Results ===

# Create a function to generate and render balance tables
create_balance_table <- function(data,
                                 treatment_var,
                                 covariates,
                                 caption_text,
                                 treatment_levels = c("Control", "Treatment")) {
    actual_levels <- levels(factor(data[[treatment_var]]))

    clean_names <- c(
        "age..mean..SD.." = "Age",
        "political_attention..mean..SD.." = "Political attention",
        "profile_gender...." = "Gender (male)",
        "X" = "Female",
        "education_recode...." = "Education level (High)",
        "X.1" = "Low",
        "X.2" = "Medium",
        "profile_work_stat...." = "Employment status (Full time student)",
        "X.3" = "Not working",
        "X.4" = "Other",
        "X.5" = "Retired",
        "X.6" = "Unemployed",
        "X.7" = "Working full time (30 or more hours per week)",
        "X.8" = "Working part time (8-29 hours a week)",
        "X.9" = "Working part time (Less than 8 hours a week)",
        "voted_ge_2024...." = "Voted in 2024 General Election (Don't know)",
        "X.10" = "No, did not vote",
        "X.11" = "Yes, voted",
        "pastvote_ge_2024...." = "Vote in 2024 General Election (Conservative)",
        "X.12" = "Don't know",
        "X.13" = "Green",
        "X.14" = "Labour",
        "X.15" = "Liberal Democrat",
        "X.16" = "Other",
        "X.17" = "Plaid Cymru",
        "X.18" = "Reform UK",
        "X.19" = "Scottish National Party (SNP)",
        "X.20" = "Skipped",
        "pastvote_EURef...." = "Vote in EU Referendum (Can’t remember)",
        "X.21" = "I did not vote",
        "X.22" = "I voted to Leave",
        "X.23" = "I voted to Remain",
        "profile_GOR...." = "Region (East Midlands)",
        "X.24" = "East of England",
        "X.25" = "London",
        "X.26" = "North East",
        "X.27" = "North West",
        "X.28" = "Scotland",
        "X.29" = "South East",
        "X.30" = "South West",
        "X.31" = "Wales",
        "X.32" = "West Midlands",
        "X.33" = "Yorkshire and the Humber"
    )

    # Create balance table object
    balance_tbl_object <- tableone::CreateTableOne(
        vars = unlist(covariates),
        strata = treatment_var,
        data = data,
        factorVars = covariates$categorical,
        test = TRUE
    )

    # Extract and format results
    balance_df <- print(balance_tbl_object,
        noSpaces = TRUE,
        showAllLevels = TRUE,
        printToggle = FALSE,
        test = TRUE
    ) %>%
        as.data.frame.matrix() %>%
        dplyr::select(actual_levels[1], actual_levels[2], "p") %>%
        setNames(c(treatment_levels[1], treatment_levels[2], "p-value")) %>%
        tibble::rownames_to_column("Variable") %>%
        dplyr::filter(Variable != "n") %>%
        dplyr::mutate(
            Variable = Variable %>%
                stringr::str_remove(fixed(" (mean (SD))")) %>%
                stringr::str_replace("=", " ") %>%
                stringr::str_remove("\\s\\(%\\)$") %>%
                dplyr::recode(!!!clean_names),
            `p-value` = as.numeric(`p-value`),
            Signif. = dplyr::case_when(
                `p-value` < 0.001 ~ "***",
                `p-value` < 0.01 ~ "**",
                `p-value` < 0.05 ~ "*",
                `p-value` > 0.05 ~ "-",
                TRUE ~ ""
            ),
            `p-value` = format.pval(`p-value`, digits = 3, eps = 0.001)
        )

    # Render table using kableExtra
    kable(balance_df,
        format = "latex",
        booktabs = TRUE,
        caption = caption_text,
        align = c("l", "c", "c", "c", "c"),
        col.names = c("Variable", treatment_levels[1], treatment_levels[2], "p-value", "Signif.")
    ) %>%
        kableExtra::kable_styling(
            font_size = 10
        ) %>%
        kableExtra::footnote(
            general = "P-values are from t-tests (continuous) or chi-squared tests (categorical) comparing groups. \\\\ Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001.",
            threeparttable = TRUE,
            escape = FALSE
        )
}
```

```{r AI Balance Table, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# === Render Balance Table for AI Treatment ===
var_name <- "ai_treatment"
pretty_name <- "AI Treatment Group"
caption <- paste0("Balance Table of Covariates by ", pretty_name)
level_names_output <- c("Control", "Treatment")

cat(create_balance_table(
    data = yougov_data,
    treatment_var = var_name,
    covariates = covariates,
    caption_text = caption,
    treatment_levels = level_names_output
))
```

```{r Label Balance Table, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# === Render Balance Table for Label Treatment ===
var_name <- "label_treatment"
pretty_name <- "Label Treatment Group"
caption <- paste0("Balance Table of Covariates by ", pretty_name)
level_names_output <- c("Control", "Treatment")

cat(create_balance_table(
    data = yougov_data,
    treatment_var = var_name,
    covariates = covariates,
    caption_text = caption,
    treatment_levels = level_names_output
))
```

## Sensitivity Analysis

Given the nature of the results often being reported as null effects, a sensitivity analysis to determine what the smallest true effect that could have detected 80% of the time is calculated.

```{r Sensitivity Analysis, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# === Sensitivity Analysis ===
```

\newpage

# Bibliography